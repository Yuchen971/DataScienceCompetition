{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stacking.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA7Vsujw0x1F",
        "colab_type": "text"
      },
      "source": [
        "# 模型融合\n",
        "简单加权融合:\n",
        "回归（分类概率）：\n",
        "\n",
        "算术平均融合（Arithmetic mean），\n",
        "\n",
        "几何平均融合（Geometric mean）；\n",
        "\n",
        "分类：\n",
        "投票（Voting)\n",
        "\n",
        "综合：排序融合(Rank averaging)，log融合\n",
        "\n",
        "stacking/blending:\n",
        "构建多层模型，并利用预测结果再拟合预测。\n",
        "\n",
        "boosting/bagging（在xgboost，Adaboost,GBDT中已经用到）:\n",
        "多树的提升方法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEveLKar1Mly",
        "colab_type": "text"
      },
      "source": [
        "# Stacking相关理论介绍\n",
        "\n",
        "1.   什么是stacking\n",
        "\n",
        "简单来说stacking就是当用初始训练数据学习出若干个基学习器后，将这几个学习器的结果作为新的训练集，来学习一个新的学习器。\n",
        "\n",
        "将个体学习器结合在一起的时候使用的方法叫做结合策略，对于分类问题，我们可以使用投票法来选择输出最多的类，对于回归问题，我们可以将分类器输出的结果求平均值。\n",
        "\n",
        "上面说的投票法和平均法都是很有效的结合策略，还有一种结合策略是使用另外一个机器学习算法来将个体机器学习器的结果结合在一起，这个方法就是stacking\n",
        "\n",
        "在stacking方法中，我们把个体学习器叫做初级学习器，用于结合的学习器叫做次级学习器或者元学习器（meta-learner）次级学习器用于训练的数据叫做次级训练集，次级训练集是在训练集上用初级学习器得到的\n",
        "\n",
        "2.   如何进行stacking\n",
        "\n",
        "算法示意图如下\n",
        "\n",
        "![替代文字](http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/2326541042/1584448806789_1ElRtHaacw.jpg)\n",
        "\n",
        "\n",
        "\n",
        "*   过程1-3是训练出来的个体学习器，也就是初级学习器\n",
        "*   过程5-9是使用训练出来的个体学习器来得预测的结果，这个预测的结果当错次级学习器的训练集。\n",
        "*   过程11是使用初级学习器预测的结果训练出次级学习器，得到我们最后训练的模型。\n",
        "\n",
        "3.   Stacking的方法讲解\n",
        "\n",
        "首先我们以一种简单但‘不那么正确的’Stacking方法说起。\n",
        "\n",
        "Stacking模型的本质是一种分层的结构，这里简单起见，只分析二级stacking。\n",
        "\n",
        "假设我们有两个基模型 Model_1, Model_2 和一个次级模型Model2\n",
        "\n",
        "Step 1. 基模型 Model_1, 对训练集train训练，然后用于预测train和test的标签列，分别是P1，T1\n",
        "\n",
        "$\\left(\\begin{array}{c}{\\vdots} \\\\ {X_{train}} \\\\ {\\vdots}\\end{array}\\right) \\overbrace{\\Longrightarrow}^{\\text {Model1_1 Train} }\\left(\\begin{array}{c}{\\vdots} \\\\ {Y}_{True} \\\\ {\\vdots}\\end{array}\\right)$\n",
        "\n",
        "训练后的模型 Model1_1 分别在train和test上预测，得到预测标签分别为P1，T1\n",
        "\n",
        "$\\left(\\begin{array}{c}{\\vdots} \\\\ {X_{train}} \\\\ {\\vdots}\\end{array}\\right) \\overbrace{\\Longrightarrow}^{\\text {Model1_1 Predict} }\\left(\\begin{array}{c}{\\vdots} \\\\ {P}_{1} \\\\ {\\vdots}\\end{array}\\right)$\n",
        "\n",
        "$\\left(\\begin{array}{c}{\\vdots} \\\\ {X_{test}} \\\\ {\\vdots}\\end{array}\\right) \\overbrace{\\Longrightarrow}^{\\text {Model1_1 Predict} }\\left(\\begin{array}{c}{\\vdots} \\\\ {T_{1}} \\\\ {\\vdots}\\end{array}\\right)$\n",
        "\n",
        "Step 2. 基模型 Model1_2 对训练集train训练，然后用于预测train和test的标签列，分别是P2，T2。\n",
        "\n",
        "model1_2 模型训练：\n",
        "\n",
        "$\\left(\\begin{array}{c}{\\vdots} \\\\ {X_{train}} \\\\ {\\vdots}\\end{array}\\right) \\overbrace{\\Longrightarrow}^{\\text {Model1_2 Train} }\\left(\\begin{array}{c}{\\vdots} \\\\ {Y}_{True} \\\\ {\\vdots}\\end{array}\\right)$\n",
        "\n",
        "训练后的模型 Model1_2 分别在train和test上预测，得到预测结果分别是P2，T2\n",
        "\n",
        "$\\left(\\begin{array}{c}{\\vdots} \\\\ {X_{train}} \\\\ {\\vdots}\\end{array}\\right) \\overbrace{\\Longrightarrow}^{\\text {Model1_2 Predict} }\\left(\\begin{array}{c}{\\vdots} \\\\ {P}_{2} \\\\ {\\vdots}\\end{array}\\right)$\n",
        "\n",
        "$\\left(\\begin{array}{c}{\\vdots} \\\\ {X_{test}} \\\\ {\\vdots}\\end{array}\\right) \\overbrace{\\Longrightarrow}^{\\text {Model1_2 Predict} }\\left(\\begin{array}{c}{\\vdots} \\\\ {T_{2}} \\\\ {\\vdots}\\end{array}\\right)$\n",
        "\n",
        "Step 3. 分别把P1，P2以及T1，T2合并，得到一个新的训练集合测试集train2，test2\n",
        "\n",
        "$\\overbrace{\\left(\\begin{array}{c}{\\vdots} \\\\ {P_{1}} \\\\ {\\vdots}\\end{array} \\begin{array}{c}{\\vdots} \\\\ {P_{2}} \\\\ {\\vdots}\\end{array} \\right)}^{\\text {Train_2 }}  \n",
        "and \n",
        "\\overbrace{\\left(\\begin{array}{c}{\\vdots} \\\\ {T_{1}} \\\\ {\\vdots}\\end{array} \\begin{array}{c}{\\vdots} \\\\ {T_{2}} \\\\ {\\vdots}\\end{array} \\right)}^{\\text {Test_2 }}$\n",
        "\n",
        "再用 次级模型 Model2 以真实训练集标签为标签训练,以train2为特征进行训练，预测test2,得到最终的测试集预测的标签列 Ypre\n",
        "\n",
        "$\\overbrace{\\left(\\begin{array}{c}{\\vdots} \\\\ {P_{1}} \\\\ {\\vdots}\\end{array} \\begin{array}{c}{\\vdots} \\\\ {P_{2}} \\\\ {\\vdots}\\end{array} \\right)}^{\\text {Train_2 }} \\overbrace{\\Longrightarrow}^{\\text {Model2 Train} }\\left(\\begin{array}{c}{\\vdots} \\\\ {Y}_{True} \\\\ {\\vdots}\\end{array}\\right)$\n",
        "\n",
        "$\\overbrace{\\left(\\begin{array}{c}{\\vdots} \\\\ {T_{1}} \\\\ {\\vdots}\\end{array} \\begin{array}{c}{\\vdots} \\\\ {T_{2}} \\\\ {\\vdots}\\end{array} \\right)}^{\\text {Test_2 }} \\overbrace{\\Longrightarrow}^{\\text {Model1_2 Predict} }\\left(\\begin{array}{c}{\\vdots} \\\\ {Y}_{Pre} \\\\ {\\vdots}\\end{array}\\right)$\n",
        "\n",
        "这就是我们两层堆叠的一种基本的原始思路想法。在不同模型预测的结果基础上再加一层模型，进行再训练，从而得到模型最终的预测。\n",
        "\n",
        "Stacking本质上就是这么直接的思路，但是直接这样有时对于如果训练集和测试集分布不那么一致的情况下是有一点问题的，其问题在于用初始模型训练的标签再利用真实标签进行再训练，毫无疑问会导致一定的模型过拟合训练集，这样或许模型在测试集上的泛化能力或者说效果会有一定的下降，因此现在的问题变成了如何降低再训练的过拟合性，这里我们一般有两种方法。\n",
        "\n",
        "*  次级模型尽量选择简单的线性模型\n",
        "*  利用K折交叉验证\n",
        "\n",
        "K-折交叉验证，训练：\n",
        "\n",
        "![替代文字](http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/2326541042/1584448819632_YvJOXMk02P.jpg)\n",
        "\n",
        "预测\n",
        "\n",
        "![](http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/2326541042/1584448826203_k8KPy9n7D9.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ8DxcgfgaGO",
        "colab_type": "text"
      },
      "source": [
        "# 5.4 代码示例\n",
        "\n",
        "## 简单加权融合，结果直接融合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh_Quouo0nLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 生成一些简单的样本数据，test_prei 代表第i个模型的预测值\n",
        "test_pre1 = [1.2, 3.2, 2.1, 6.2]\n",
        "test_pre2 = [0.9, 3.1, 2.0, 5.9]\n",
        "test_pre3 = [1.1, 2.9, 2.2, 6.0]\n",
        "\n",
        "# y_test_true 代表第模型的真实值\n",
        "y_test_true = [1, 3, 2, 6] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xGEpsXsgqWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "## 定义结果的加权平均函数\n",
        "def Weighted_method(test_pre1,test_pre2,test_pre3,w=[1/3,1/3,1/3]):\n",
        "    Weighted_result = w[0]*pd.Series(test_pre1)+w[1]*pd.Series(test_pre2)+w[2]*pd.Series(test_pre3)\n",
        "    return Weighted_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVsMXgNHgsJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "86f5880e-08e6-4680-8c29-c117a1c0f060"
      },
      "source": [
        "from sklearn import metrics\n",
        "# 各模型的预测结果计算MAE\n",
        "print('Pred1 MAE:',metrics.mean_absolute_error(y_test_true, test_pre1))\n",
        "print('Pred2 MAE:',metrics.mean_absolute_error(y_test_true, test_pre2))\n",
        "print('Pred3 MAE:',metrics.mean_absolute_error(y_test_true, test_pre3))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred1 MAE: 0.1750000000000001\n",
            "Pred2 MAE: 0.07499999999999993\n",
            "Pred3 MAE: 0.10000000000000009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2MHGs-_gy6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4233898b-1dda-472c-c0b5-77b9c3c045c7"
      },
      "source": [
        "## 根据加权计算MAE\n",
        "w = [0.3,0.4,0.3] # 定义比重权值\n",
        "Weighted_pre = Weighted_method(test_pre1,test_pre2,test_pre3,w)\n",
        "print('Weighted_pre MAE:',metrics.mean_absolute_error(y_test_true, Weighted_pre))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weighted_pre MAE: 0.05750000000000027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU2cK875hR4v",
        "colab_type": "text"
      },
      "source": [
        "可以发现加权结果相对于之前的结果是有提升的，这种我们称其为简单的加权平均。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmq-PoKThU4w",
        "colab_type": "text"
      },
      "source": [
        "还有一些特殊的形式，比如mean平均，median平均"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YOOAGaGg2i3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 定义结果的加权平均函数\n",
        "def Mean_method(test_pre1,test_pre2,test_pre3):\n",
        "    Mean_result = pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).mean(axis=1)\n",
        "    return Mean_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvSkpA-nhXCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bb2a0a0-8e31-497d-c1db-51600b957dd4"
      },
      "source": [
        "Mean_pre = Mean_method(test_pre1,test_pre2,test_pre3)\n",
        "print('Mean_pre MAE:',metrics.mean_absolute_error(y_test_true, Mean_pre))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean_pre MAE: 0.06666666666666693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VBWlAlKhbJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 定义结果的加权平均函数\n",
        "def Median_method(test_pre1,test_pre2,test_pre3):\n",
        "    Median_result = pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).median(axis=1)\n",
        "    return Median_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmJP8vGthh_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fad1b3de-4742-4d3b-f944-feb257018041"
      },
      "source": [
        "Median_pre = Median_method(test_pre1,test_pre2,test_pre3)\n",
        "print('Median_pre MAE:',metrics.mean_absolute_error(y_test_true, Median_pre))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Median_pre MAE: 0.07500000000000007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URiB5IGshopd",
        "colab_type": "text"
      },
      "source": [
        "## Stacking融合（回归）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf_bQK6ihif5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "def Stacking_method(train_reg1,train_reg2,train_reg3,y_train_true,test_pre1,test_pre2,test_pre3,model_L2= linear_model.LinearRegression()):\n",
        "    model_L2.fit(pd.concat([pd.Series(train_reg1),pd.Series(train_reg2),pd.Series(train_reg3)],axis=1).values,y_train_true)\n",
        "    Stacking_result = model_L2.predict(pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).values)\n",
        "    return Stacking_result\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdWBB8sHhvET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 生成一些简单的样本数据，test_prei 代表第i个模型的预测值\n",
        "train_reg1 = [3.2, 8.2, 9.1, 5.2]\n",
        "train_reg2 = [2.9, 8.1, 9.0, 4.9]\n",
        "train_reg3 = [3.1, 7.9, 9.2, 5.0]\n",
        "# y_test_true 代表第模型的真实值\n",
        "y_train_true = [3, 8, 9, 5] \n",
        "\n",
        "test_pre1 = [1.2, 3.2, 2.1, 6.2]\n",
        "test_pre2 = [0.9, 3.1, 2.0, 5.9]\n",
        "test_pre3 = [1.1, 2.9, 2.2, 6.0]\n",
        "\n",
        "# y_test_true 代表第模型的真实值\n",
        "y_test_true = [1, 3, 2, 6] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMHiC9eMiAZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_L2= linear_model.LinearRegression()\n",
        "Stacking_pre = Stacking_method(train_reg1,train_reg2,train_reg3,y_train_true,\n",
        "                               test_pre1,test_pre2,test_pre3,model_L2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeSWlqH0iCT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "545d4581-9a50-4be3-933b-aaac2b40833d"
      },
      "source": [
        "print('Stacking_pre MAE:',metrics.mean_absolute_error(y_test_true, Stacking_pre))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stacking_pre MAE: 0.042134831460675204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l27fH8h5iW-9",
        "colab_type": "text"
      },
      "source": [
        "可以发现模型结果相对于之前有进一步的提升，这是我们需要注意的一点是，对于第二层Stacking的模型不宜选取的过于复杂，这样会导致模型在训练集上过拟合，从而使得在测试集上并不能达到很好的效果。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2XaHBGLid9I",
        "colab_type": "text"
      },
      "source": [
        "## 5.4.2 分类模型融合\n",
        "\n",
        "对于分类，同样的我们可以使用融合方法，比如简单投票，stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krDLCt3TiEhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.metrics import accuracy_score,roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjuPDpj0ioxy",
        "colab_type": "text"
      },
      "source": [
        "### voting 投票机制"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URpeSkSEiuAO",
        "colab_type": "text"
      },
      "source": [
        "Voting即投票机制，分为软投票和硬投票两种，其原理采用少数服从多数的思想。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPilxtD3immL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2927153d-38c6-49fa-9f61-ffa205d7ae7f"
      },
      "source": [
        "'''\n",
        "硬投票：对多个模型直接进行投票，不区分模型结果的相对重要度，最终投票数最多的类为最终被预测的类。\n",
        "'''\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "x=iris.data\n",
        "y=iris.target\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)\n",
        "\n",
        "clf1 = XGBClassifier(\n",
        "    learning_rate=0.1, \n",
        "    n_estimators=150, \n",
        "    max_depth=3,\n",
        "    min_child_weight=2, \n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.6,\n",
        "    objective='binary:logistic'\n",
        ")\n",
        "clf2 = RandomForestClassifier(\n",
        "    n_estimators=50, \n",
        "    max_depth=1, \n",
        "    min_samples_split=4,\n",
        "    min_samples_leaf=63,oob_score=True\n",
        ")\n",
        "clf3 = SVC(C=0.1)\n",
        "\n",
        "# 硬投票\n",
        "eclf = VotingClassifier(\n",
        "    estimators=[('xgb', clf1), ('rf', clf2), ('svc', clf3)], \n",
        "    voting='hard'\n",
        ")\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['XGBBoosting', 'Random Forest', 'SVM', 'Ensemble']):\n",
        "    scores = cross_val_score(clf, x, y, cv=5, scoring='accuracy')\n",
        "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.95 (+/- 0.03) [XGBBoosting]\n",
            "Accuracy: 0.33 (+/- 0.00) [Random Forest]\n",
            "Accuracy: 0.92 (+/- 0.03) [SVM]\n",
            "Accuracy: 0.94 (+/- 0.04) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOfsYVc6jGkY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0ef67ddd-c91d-4f93-e1e7-2b3db6d2fc6f"
      },
      "source": [
        "'''\n",
        "软投票：和硬投票原理相同，增加了设置权重的功能，可以为不同模型设置不同权重，进而区别模型不同的重要度。\n",
        "'''\n",
        "x=iris.data\n",
        "y=iris.target\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)\n",
        "\n",
        "clf1 = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=3, min_child_weight=2, subsample=0.8,\n",
        "                     colsample_bytree=0.8, objective='binary:logistic')\n",
        "clf2 = RandomForestClassifier(n_estimators=50, max_depth=1, min_samples_split=4,\n",
        "                              min_samples_leaf=63,oob_score=True)\n",
        "clf3 = SVC(C=0.1, probability=True)\n",
        "\n",
        "# 软投票\n",
        "eclf = VotingClassifier(estimators=[('xgb', clf1), ('rf', clf2), ('svc', clf3)], voting='soft', weights=[2, 1, 1])\n",
        "clf1.fit(x_train, y_train)\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['XGBBoosting', 'Random Forest', 'SVM', 'Ensemble']):\n",
        "    scores = cross_val_score(clf, x, y, cv=5, scoring='accuracy')\n",
        "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.96 (+/- 0.02) [XGBBoosting]\n",
            "Accuracy: 0.33 (+/- 0.00) [Random Forest]\n",
            "Accuracy: 0.92 (+/- 0.03) [SVM]\n",
            "Accuracy: 0.96 (+/- 0.02) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0suwVgDCj1QM",
        "colab_type": "text"
      },
      "source": [
        "### 分类的Stacking、Blending融合"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYFcztC9j6dt",
        "colab_type": "text"
      },
      "source": [
        "stacking是一种分层模型集成框架。\n",
        "\n",
        "以两层为例，第一层由多个基学习器组成，其输入为原始训练集，第二层的模型则是以第一层基学习器的输出作为训练集进行再训练，从而得到完整的stacking模型, stacking两层模型都使用了全部的训练数据。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCVNfIgvjtNg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "de922617-8995-43f3-defb-d37b63d1babb"
      },
      "source": [
        "'''\n",
        "5-Fold Stacking\n",
        "'''\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier,GradientBoostingClassifier\n",
        "import pandas as pd\n",
        "#创建训练的数据集\n",
        "data_0 = iris.data\n",
        "data = data_0[:100,:]\n",
        "\n",
        "target_0 = iris.target\n",
        "target = target_0[:100]\n",
        "\n",
        "#模型融合中使用到的各个单模型\n",
        "clfs = [LogisticRegression(solver='lbfgs'),\n",
        "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
        "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]\n",
        " \n",
        "#切分一部分数据作为测试集\n",
        "X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=2020)\n",
        "\n",
        "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
        "dataset_blend_test = np.zeros((X_predict.shape[0], len(clfs)))\n",
        "\n",
        "#5折stacking\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits)\n",
        "skf = skf.split(X, y)\n",
        "\n",
        "for j, clf in enumerate(clfs):\n",
        "    #依次训练各个单模型\n",
        "    dataset_blend_test_j = np.zeros((X_predict.shape[0], len(clfs)))\n",
        "    for i, (train, test) in enumerate(skf):\n",
        "        #5-Fold交叉训练，使用第i个部分作为预测，剩余的部分来训练模型，获得其预测的输出作为第i部分的新特征。\n",
        "        X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_submission = clf.predict_proba(X_test)[:, 1]\n",
        "        dataset_blend_train[test, j] = y_submission\n",
        "        dataset_blend_test_j[:, i] = clf.predict_proba(X_predict)[:, 1]\n",
        "    #对于测试集，直接用这k个模型的预测值均值作为新的特征。\n",
        "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
        "    print(\"val auc Score: %f\" % roc_auc_score(y_predict, dataset_blend_test[:, j]))\n",
        "\n",
        "clf = LogisticRegression(solver='lbfgs')\n",
        "clf.fit(dataset_blend_train, y)\n",
        "y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
        "\n",
        "print(\"Val auc Score of Stacking: %f\" % (roc_auc_score(y_predict, y_submission)))\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val auc Score: 1.000000\n",
            "val auc Score: 0.500000\n",
            "val auc Score: 0.500000\n",
            "val auc Score: 0.500000\n",
            "val auc Score: 0.500000\n",
            "Val auc Score of Stacking: 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15EERYIVlaoN",
        "colab_type": "text"
      },
      "source": [
        "Blending，其实和Stacking是一种类似的多层模型融合的形式\n",
        "\n",
        "其主要思路是把原始的训练集先分成两部分，比如70%的数据作为新的训练集，剩下30%的数据作为测试集。\n",
        "\n",
        "在第一层，我们在这70%的数据上训练多个模型，然后去预测那30%数据的label，同时也预测test集的label。\n",
        "\n",
        "在第二层，我们就直接用这30%数据在第一层预测的结果做为新特征继续训练，然后用test集第一层预测的label做特征，用第二层训练的模型做进一步预测\n",
        "\n",
        "其优点在于：\n",
        "\n",
        "1.比stacking简单（因为不用进行k次的交叉验证来获得stacker feature）\n",
        "2.避开了一个信息泄露问题：generlizers和stacker使用了不一样的数据集\n",
        "缺点在于：\n",
        "\n",
        "1.使用了很少的数据（第二阶段的blender只使用training set10%的量）\n",
        "2.blender可能会过拟合\n",
        "3.stacking使用多次的交叉验证会比较稳健 ''"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0siVuEx2kiZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "82e5c6fd-263e-4823-8e18-7a862b2acfc5"
      },
      "source": [
        "'''\n",
        "Blending\n",
        "'''\n",
        " \n",
        "#创建训练的数据集\n",
        "#创建训练的数据集\n",
        "data_0 = iris.data\n",
        "data = data_0[:100,:]\n",
        "\n",
        "target_0 = iris.target\n",
        "target = target_0[:100]\n",
        " \n",
        "#模型融合中使用到的各个单模型\n",
        "clfs = [LogisticRegression(solver='lbfgs'),\n",
        "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
        "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        #ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
        "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]\n",
        " \n",
        "#切分一部分数据作为测试集\n",
        "X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=2020)\n",
        "\n",
        "#切分训练数据集为d1,d2两部分\n",
        "X_d1, X_d2, y_d1, y_d2 = train_test_split(X, y, test_size=0.5, random_state=2020)\n",
        "dataset_d1 = np.zeros((X_d2.shape[0], len(clfs)))\n",
        "dataset_d2 = np.zeros((X_predict.shape[0], len(clfs)))\n",
        " \n",
        "for j, clf in enumerate(clfs):\n",
        "    #依次训练各个单模型\n",
        "    clf.fit(X_d1, y_d1)\n",
        "    y_submission = clf.predict_proba(X_d2)[:, 1]\n",
        "    dataset_d1[:, j] = y_submission\n",
        "    #对于测试集，直接用这k个模型的预测值作为新的特征。\n",
        "    dataset_d2[:, j] = clf.predict_proba(X_predict)[:, 1]\n",
        "    print(\"val auc Score: %f\" % roc_auc_score(y_predict, dataset_d2[:, j]))\n",
        "\n",
        "#融合使用的模型\n",
        "clf = GradientBoostingClassifier(learning_rate=0.02, subsample=0.5, max_depth=6, n_estimators=30)\n",
        "clf.fit(dataset_d1, y_d2)\n",
        "y_submission = clf.predict_proba(dataset_d2)[:, 1]\n",
        "print(\"Val auc Score of Blending: %f\" % (roc_auc_score(y_predict, y_submission)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val auc Score: 1.000000\n",
            "val auc Score: 1.000000\n",
            "val auc Score: 1.000000\n",
            "val auc Score: 1.000000\n",
            "val auc Score: 1.000000\n",
            "Val auc Score of Blending: 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIHSqcmolhBC",
        "colab_type": "text"
      },
      "source": [
        "参考博客：https://blog.csdn.net/Noob_daniel/article/details/76087829"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtxMAZbVliqZ",
        "colab_type": "text"
      },
      "source": [
        "### 分类的stacking融合 利用mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOIz-GVwlejQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "2256b60b-a499-4ade-d27f-952fc66957a3"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import itertools\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from mlxtend.plotting import plot_learning_curves\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "# 以python自带的鸢尾花数据集为例\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data[:, 1:3], iris.target\n",
        "\n",
        "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
        "clf2 = RandomForestClassifier(random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "lr = LogisticRegression()\n",
        "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n",
        "                          meta_classifier=lr)\n",
        "\n",
        "label = ['KNN', 'Random Forest', 'Naive Bayes', 'Stacking Classifier']\n",
        "clf_list = [clf1, clf2, clf3, sclf]\n",
        "\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "gs = gridspec.GridSpec(2, 2)\n",
        "grid = itertools.product([0,1],repeat=2)\n",
        "\n",
        "clf_cv_mean = []\n",
        "clf_cv_std = []\n",
        "for clf, label, grd in zip(clf_list, label, grid):\n",
        "        \n",
        "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
        "    print(\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
        "    clf_cv_mean.append(scores.mean())\n",
        "    clf_cv_std.append(scores.std())\n",
        "        \n",
        "    clf.fit(X, y)\n",
        "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf)\n",
        "    plt.title(label)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.91 (+/- 0.01) [KNN]\n",
            "Accuracy: 0.95 (+/- 0.01) [Random Forest]\n",
            "Accuracy: 0.91 (+/- 0.02) [Naive Bayes]\n",
            "Accuracy: 0.95 (+/- 0.02) [Stacking Classifier]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAHiCAYAAAD8s1iEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEDA/wFT+EBsHiH5HgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x576 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCivObBAlrb1",
        "colab_type": "text"
      },
      "source": [
        "## 一些其他方法\n",
        "\n",
        "**将特征放进模型中预测，并将预测结果变换并作为新的特征加入原有特征中再经过模型预测结果（Stacking变化）**\n",
        "\n",
        "（可以反复预测多次将结果加入最后的特征中）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvGBxThAlpLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Ensemble_add_feature(train,test,target,clfs):\n",
        "    \n",
        "    # n_flods = 5\n",
        "    # skf = list(StratifiedKFold(y, n_folds=n_flods))\n",
        "\n",
        "    train_ = np.zeros((train.shape[0],len(clfs*2)))\n",
        "    test_ = np.zeros((test.shape[0],len(clfs*2)))\n",
        "\n",
        "    for j,clf in enumerate(clfs):\n",
        "        '''依次训练各个单模型'''\n",
        "        # print(j, clf)\n",
        "        '''使用第1个部分作为预测，第2部分来训练模型，获得其预测的输出作为第2部分的新特征。'''\n",
        "        # X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
        "\n",
        "        clf.fit(train,target)\n",
        "        y_train = clf.predict(train)\n",
        "        y_test = clf.predict(test)\n",
        "\n",
        "        ## 新特征生成\n",
        "        train_[:,j*2] = y_train**2\n",
        "        test_[:,j*2] = y_test**2\n",
        "        train_[:, j+1] = np.exp(y_train)\n",
        "        test_[:, j+1] = np.exp(y_test)\n",
        "        # print(\"val auc Score: %f\" % r2_score(y_predict, dataset_d2[:, j]))\n",
        "        print('Method ',j)\n",
        "    \n",
        "    train_ = pd.DataFrame(train_)\n",
        "    test_ = pd.DataFrame(test_)\n",
        "    return train_,test_\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WI9P8uPmBWx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fade8fb8-4380-425d-d24a-4d938dbb9d0d"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression()\n",
        "\n",
        "data_0 = iris.data\n",
        "data = data_0[:100,:]\n",
        "\n",
        "target_0 = iris.target\n",
        "target = target_0[:100]\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(data,target,test_size=0.3)\n",
        "x_train = pd.DataFrame(x_train) ; x_test = pd.DataFrame(x_test)\n",
        "\n",
        "#模型融合中使用到的各个单模型\n",
        "clfs = [LogisticRegression(),\n",
        "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
        "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]\n",
        "\n",
        "New_train,New_test = Ensemble_add_feature(x_train,x_test,y_train,clfs)\n",
        "\n",
        "clf = LogisticRegression()\n",
        "# clf = GradientBoostingClassifier(learning_rate=0.02, subsample=0.5, max_depth=6, n_estimators=30)\n",
        "clf.fit(New_train, y_train)\n",
        "y_emb = clf.predict_proba(New_test)[:, 1]\n",
        "\n",
        "print(\"Val auc Score of stacking: %f\" % (roc_auc_score(y_test, y_emb)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Method  0\n",
            "Method  1\n",
            "Method  2\n",
            "Method  3\n",
            "Method  4\n",
            "Val auc Score of stacking: 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPakCybBmE-y",
        "colab_type": "text"
      },
      "source": [
        "# 赛题示例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D09zee7jmD0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import matplotlib.gridspec as gridspec\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# from mlxtend.classifier import StackingClassifier\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "# from mlxtend.plotting import plot_learning_curves\n",
        "# from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import preprocessing\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.decomposition import PCA,FastICA,FactorAnalysis,SparsePCA\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFXyQMfemKaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "46aef26a-c95c-4059-9c62-4c2fd0bd35a0"
      },
      "source": [
        "#数据读取\n",
        "Train_data = pd.read_csv('/content/drive/My Drive/Tianchi/used_car_train_20200313.csv', sep = ' ')\n",
        "TestA_data = pd.read_csv('/content/drive/My Drive/Tianchi/used_car_testA_20200313.csv', sep = ' ')\n",
        "\n",
        "print(Train_data.shape)\n",
        "print(TestA_data.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 31)\n",
            "(50000, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KV8fzl3mc1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "e0e1315f-f1af-4a64-f3da-c92c810e21bf"
      },
      "source": [
        "Train_data.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SaleID</th>\n",
              "      <th>name</th>\n",
              "      <th>regDate</th>\n",
              "      <th>model</th>\n",
              "      <th>brand</th>\n",
              "      <th>bodyType</th>\n",
              "      <th>fuelType</th>\n",
              "      <th>gearbox</th>\n",
              "      <th>power</th>\n",
              "      <th>kilometer</th>\n",
              "      <th>notRepairedDamage</th>\n",
              "      <th>regionCode</th>\n",
              "      <th>seller</th>\n",
              "      <th>offerType</th>\n",
              "      <th>creatDate</th>\n",
              "      <th>price</th>\n",
              "      <th>v_0</th>\n",
              "      <th>v_1</th>\n",
              "      <th>v_2</th>\n",
              "      <th>v_3</th>\n",
              "      <th>v_4</th>\n",
              "      <th>v_5</th>\n",
              "      <th>v_6</th>\n",
              "      <th>v_7</th>\n",
              "      <th>v_8</th>\n",
              "      <th>v_9</th>\n",
              "      <th>v_10</th>\n",
              "      <th>v_11</th>\n",
              "      <th>v_12</th>\n",
              "      <th>v_13</th>\n",
              "      <th>v_14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>736</td>\n",
              "      <td>20040402</td>\n",
              "      <td>30.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60</td>\n",
              "      <td>12.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1046</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20160404</td>\n",
              "      <td>1850</td>\n",
              "      <td>43.357796</td>\n",
              "      <td>3.966344</td>\n",
              "      <td>0.050257</td>\n",
              "      <td>2.159744</td>\n",
              "      <td>1.143786</td>\n",
              "      <td>0.235676</td>\n",
              "      <td>0.101988</td>\n",
              "      <td>0.129549</td>\n",
              "      <td>0.022816</td>\n",
              "      <td>0.097462</td>\n",
              "      <td>-2.881803</td>\n",
              "      <td>2.804097</td>\n",
              "      <td>-2.420821</td>\n",
              "      <td>0.795292</td>\n",
              "      <td>0.914762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2262</td>\n",
              "      <td>20030301</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-</td>\n",
              "      <td>4366</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20160309</td>\n",
              "      <td>3600</td>\n",
              "      <td>45.305273</td>\n",
              "      <td>5.236112</td>\n",
              "      <td>0.137925</td>\n",
              "      <td>1.380657</td>\n",
              "      <td>-1.422165</td>\n",
              "      <td>0.264777</td>\n",
              "      <td>0.121004</td>\n",
              "      <td>0.135731</td>\n",
              "      <td>0.026597</td>\n",
              "      <td>0.020582</td>\n",
              "      <td>-4.900482</td>\n",
              "      <td>2.096338</td>\n",
              "      <td>-1.030483</td>\n",
              "      <td>-1.722674</td>\n",
              "      <td>0.245522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>14874</td>\n",
              "      <td>20040403</td>\n",
              "      <td>115.0</td>\n",
              "      <td>15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>163</td>\n",
              "      <td>12.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2806</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20160402</td>\n",
              "      <td>6222</td>\n",
              "      <td>45.978359</td>\n",
              "      <td>4.823792</td>\n",
              "      <td>1.319524</td>\n",
              "      <td>-0.998467</td>\n",
              "      <td>-0.996911</td>\n",
              "      <td>0.251410</td>\n",
              "      <td>0.114912</td>\n",
              "      <td>0.165147</td>\n",
              "      <td>0.062173</td>\n",
              "      <td>0.027075</td>\n",
              "      <td>-4.846749</td>\n",
              "      <td>1.803559</td>\n",
              "      <td>1.565330</td>\n",
              "      <td>-0.832687</td>\n",
              "      <td>-0.229963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>71865</td>\n",
              "      <td>19960908</td>\n",
              "      <td>109.0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>193</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>434</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20160312</td>\n",
              "      <td>2400</td>\n",
              "      <td>45.687478</td>\n",
              "      <td>4.492574</td>\n",
              "      <td>-0.050616</td>\n",
              "      <td>0.883600</td>\n",
              "      <td>-2.228079</td>\n",
              "      <td>0.274293</td>\n",
              "      <td>0.110300</td>\n",
              "      <td>0.121964</td>\n",
              "      <td>0.033395</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-4.509599</td>\n",
              "      <td>1.285940</td>\n",
              "      <td>-0.501868</td>\n",
              "      <td>-2.438353</td>\n",
              "      <td>-0.478699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>111080</td>\n",
              "      <td>20120103</td>\n",
              "      <td>110.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6977</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20160313</td>\n",
              "      <td>5200</td>\n",
              "      <td>44.383511</td>\n",
              "      <td>2.031433</td>\n",
              "      <td>0.572169</td>\n",
              "      <td>-1.571239</td>\n",
              "      <td>2.246088</td>\n",
              "      <td>0.228036</td>\n",
              "      <td>0.073205</td>\n",
              "      <td>0.091880</td>\n",
              "      <td>0.078819</td>\n",
              "      <td>0.121534</td>\n",
              "      <td>-1.896240</td>\n",
              "      <td>0.910783</td>\n",
              "      <td>0.931110</td>\n",
              "      <td>2.834518</td>\n",
              "      <td>1.923482</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SaleID    name   regDate  model  ...      v_11      v_12      v_13      v_14\n",
              "0       0     736  20040402   30.0  ...  2.804097 -2.420821  0.795292  0.914762\n",
              "1       1    2262  20030301   40.0  ...  2.096338 -1.030483 -1.722674  0.245522\n",
              "2       2   14874  20040403  115.0  ...  1.803559  1.565330 -0.832687 -0.229963\n",
              "3       3   71865  19960908  109.0  ...  1.285940 -0.501868 -2.438353 -0.478699\n",
              "4       4  111080  20120103  110.0  ...  0.910783  0.931110  2.834518  1.923482\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1ZUB0aqmp58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "57939d3d-7f1c-4157-dc2e-4264faa3c1d1"
      },
      "source": [
        "numerical_cols = Train_data.select_dtypes(exclude = 'object').columns\n",
        "print(numerical_cols)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['SaleID', 'name', 'regDate', 'model', 'brand', 'bodyType', 'fuelType',\n",
            "       'gearbox', 'power', 'kilometer', 'regionCode', 'seller', 'offerType',\n",
            "       'creatDate', 'price', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 'v_6',\n",
            "       'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13', 'v_14'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imVCXIgDmrXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_cols = [col for col in numerical_cols if col not in ['SaleID','name','regDate','price']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-kcjPxhmtwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a00e3378-93c4-4c17-e7b8-9586ed0f8622"
      },
      "source": [
        "X_data = Train_data[feature_cols]\n",
        "Y_data = Train_data['price']\n",
        "\n",
        "X_test  = TestA_data[feature_cols]\n",
        "\n",
        "print('X train shape:',X_data.shape)\n",
        "print('X test shape:',X_test.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape: (150000, 26)\n",
            "X test shape: (50000, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sOLlmIvmvL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Sta_inf(data):\n",
        "    print('_min',np.min(data))\n",
        "    print('_max:',np.max(data))\n",
        "    print('_mean',np.mean(data))\n",
        "    print('_ptp',np.ptp(data))\n",
        "    print('_std',np.std(data))\n",
        "    print('_var',np.var(data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3ZWeWIXmwkd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e769f484-86b9-4a92-a41f-58587876ca07"
      },
      "source": [
        "print('Sta of label:')\n",
        "Sta_inf(Y_data)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sta of label:\n",
            "_min 11\n",
            "_max: 99999\n",
            "_mean 5923.327333333334\n",
            "_ptp 99988\n",
            "_std 7501.973469876438\n",
            "_var 56279605.94272992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db1-V9Z0okTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_data = X_data.fillna(-1)\n",
        "X_test = X_test.fillna(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmlfrZ5TmyfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_lr(x_train,y_train):\n",
        "    reg_model = linear_model.LinearRegression()\n",
        "    reg_model.fit(x_train,y_train)\n",
        "    return reg_model\n",
        "\n",
        "def build_model_ridge(x_train,y_train):\n",
        "    reg_model = linear_model.Ridge(alpha=0.8)#alphas=range(1,100,5)\n",
        "    reg_model.fit(x_train,y_train)\n",
        "    return reg_model\n",
        "\n",
        "def build_model_lasso(x_train,y_train):\n",
        "    reg_model = linear_model.LassoCV()\n",
        "    reg_model.fit(x_train,y_train)\n",
        "    return reg_model\n",
        "\n",
        "def build_model_gbdt(x_train,y_train):\n",
        "    estimator =GradientBoostingRegressor(loss='ls',subsample= 0.85,max_depth= 5,n_estimators = 100)\n",
        "    param_grid = { \n",
        "            'learning_rate': [0.05,0.08,0.1,0.2],\n",
        "            }\n",
        "    gbdt = GridSearchCV(estimator, param_grid,cv=3)\n",
        "    gbdt.fit(x_train,y_train)\n",
        "    print(gbdt.best_params_)\n",
        "    # print(gbdt.best_estimator_ )\n",
        "    return gbdt\n",
        "\n",
        "def build_model_xgb(x_train,y_train):\n",
        "    model = xgb.XGBRegressor(n_estimators=120, learning_rate=0.08, gamma=0, subsample=0.8,\\\n",
        "        colsample_bytree=0.9, max_depth=5) #, objective ='reg:squarederror'\n",
        "    model.fit(x_train, y_train)\n",
        "    return model\n",
        "\n",
        "def build_model_lgb(x_train,y_train):\n",
        "    estimator = lgb.LGBMRegressor(num_leaves=63,n_estimators = 100)\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "    }\n",
        "    gbm = GridSearchCV(estimator, param_grid)\n",
        "    gbm.fit(x_train, y_train)\n",
        "    return gbm\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnNXiCUpm2Qj",
        "colab_type": "text"
      },
      "source": [
        "## XGBoost五折交叉回归验证实现"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpQx3NR7m1Gq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "71db7992-ece6-4f3c-8177-23b52c5fc843"
      },
      "source": [
        "## xgb\n",
        "xgr = xgb.XGBRegressor(n_estimators=120, learning_rate=0.1, subsample=0.8,\\\n",
        "        colsample_bytree=0.9, max_depth=7) # ,objective ='reg:squarederror'\n",
        "\n",
        "scores_train = []\n",
        "scores = []\n",
        "\n",
        "## 5折交叉验证方式\n",
        "sk=StratifiedKFold(n_splits=5,shuffle=True,random_state=0)\n",
        "for train_ind,val_ind in sk.split(X_data,Y_data):\n",
        "    \n",
        "    train_x=X_data.iloc[train_ind].values\n",
        "    train_y=Y_data.iloc[train_ind]\n",
        "    val_x=X_data.iloc[val_ind].values\n",
        "    val_y=Y_data.iloc[val_ind]\n",
        "    \n",
        "    xgr.fit(train_x,train_y)\n",
        "    pred_train_xgb=xgr.predict(train_x)\n",
        "    pred_xgb=xgr.predict(val_x)\n",
        "    \n",
        "    score_train = mean_absolute_error(train_y,pred_train_xgb)\n",
        "    scores_train.append(score_train)\n",
        "    score = mean_absolute_error(val_y,pred_xgb)\n",
        "    scores.append(score)\n",
        "\n",
        "print('Train mae:',np.mean(score_train))\n",
        "print('Val mae',np.mean(scores))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[08:39:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:40:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:41:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:41:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:42:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Train mae: 594.4890495346745\n",
            "Val mae 694.5823127983205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQuR4bE0m-SL",
        "colab_type": "text"
      },
      "source": [
        "### 划分数据，并用多种方法训练和预测"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqKxygP1m8Wn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ff955146-dd4d-4a2d-f77d-12afab67c520"
      },
      "source": [
        "## Split data with val\n",
        "x_train,x_val,y_train,y_val = train_test_split(X_data,Y_data,test_size=0.3)\n",
        "\n",
        "## Train and Predict\n",
        "print('Predict LR...')\n",
        "model_lr = build_model_lr(x_train,y_train)\n",
        "val_lr = model_lr.predict(x_val)\n",
        "subA_lr = model_lr.predict(X_test)\n",
        "\n",
        "print('Predict Ridge...')\n",
        "model_ridge = build_model_ridge(x_train,y_train)\n",
        "val_ridge = model_ridge.predict(x_val)\n",
        "subA_ridge = model_ridge.predict(X_test)\n",
        "\n",
        "print('Predict Lasso...')\n",
        "model_lasso = build_model_lasso(x_train,y_train)\n",
        "val_lasso = model_lasso.predict(x_val)\n",
        "subA_lasso = model_lasso.predict(X_test)\n",
        "\n",
        "print('Predict GBDT...')\n",
        "model_gbdt = build_model_gbdt(x_train,y_train)\n",
        "val_gbdt = model_gbdt.predict(x_val)\n",
        "subA_gbdt = model_gbdt.predict(X_test)\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predict LR...\n",
            "Predict Ridge...\n",
            "Predict Lasso...\n",
            "Predict GBDT...\n",
            "{'learning_rate': 0.2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDjNwEmunGKN",
        "colab_type": "text"
      },
      "source": [
        "### 一般比赛中效果最显著的两种方法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn-nLrbanEvM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "92731b87-7949-4c93-bae9-cd4a18b490fd"
      },
      "source": [
        "print('predict XGB...')\n",
        "model_xgb = build_model_xgb(x_train,y_train)\n",
        "val_xgb = model_xgb.predict(x_val)\n",
        "subA_xgb = model_xgb.predict(X_test)\n",
        "\n",
        "print('predict lgb...')\n",
        "model_lgb = build_model_lgb(x_train,y_train)\n",
        "val_lgb = model_lgb.predict(x_val)\n",
        "subA_lgb = model_lgb.predict(X_test)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict XGB...\n",
            "[09:00:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "predict lgb...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gXcLpgBnLyl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6579af24-4069-43f0-93a1-30452a02c738"
      },
      "source": [
        "print('Sta inf of lgb:')\n",
        "Sta_inf(subA_lgb)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sta inf of lgb:\n",
            "_min -103.16213613404301\n",
            "_max: 89005.19704227413\n",
            "_mean 5920.827044859752\n",
            "_ptp 89108.35917840817\n",
            "_std 7349.62235477467\n",
            "_var 54016948.75780357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuDacrXbnOjl",
        "colab_type": "text"
      },
      "source": [
        "##  加权融合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDR3K4gCnNb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "46953115-bbc5-48d7-bf3b-f79768e9ceac"
      },
      "source": [
        "def Weighted_method(test_pre1,test_pre2,test_pre3,w=[1/3,1/3,1/3]):\n",
        "    Weighted_result = w[0]*pd.Series(test_pre1)+w[1]*pd.Series(test_pre2)+w[2]*pd.Series(test_pre3)\n",
        "    return Weighted_result\n",
        "\n",
        "## Init the Weight\n",
        "w = [0.3,0.4,0.3]\n",
        "\n",
        "## 测试验证集准确度\n",
        "val_pre = Weighted_method(val_lgb,val_xgb,val_gbdt,w)\n",
        "MAE_Weighted = mean_absolute_error(y_val,val_pre)\n",
        "print('MAE of Weighted of val:',MAE_Weighted)\n",
        "\n",
        "## 预测数据部分\n",
        "subA = Weighted_method(subA_lgb,subA_xgb,subA_gbdt,w)\n",
        "print('Sta inf:')\n",
        "Sta_inf(subA)\n",
        "## 生成提交文件\n",
        "sub = pd.DataFrame()\n",
        "sub['SaleID'] = X_test.index\n",
        "sub['price'] = subA\n",
        "sub.to_csv('./sub_Weighted.csv',index=False)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE of Weighted of val: 719.3507908222824\n",
            "Sta inf:\n",
            "_min -107.90007231254327\n",
            "_max: 88783.15172327406\n",
            "_mean 5925.473795497284\n",
            "_ptp 88891.05179558661\n",
            "_std 7349.768215796452\n",
            "_var 54019092.825931765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByFV9E7JnUuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aec73510-89f8-4038-ff79-23cd40b939b1"
      },
      "source": [
        "## 与简单的LR（线性回归）进行对比\n",
        "val_lr_pred = model_lr.predict(x_val)\n",
        "MAE_lr = mean_absolute_error(y_val,val_lr_pred)\n",
        "print('MAE of lr:',MAE_lr)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE of lr: 2586.179564593972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDVzgvj3nXG4",
        "colab_type": "text"
      },
      "source": [
        "## Stacking融合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-AqSkennWAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Starking\n",
        "\n",
        "## 第一层\n",
        "train_lgb_pred = model_lgb.predict(x_train)\n",
        "train_xgb_pred = model_xgb.predict(x_train)\n",
        "train_gbdt_pred = model_gbdt.predict(x_train)\n",
        "\n",
        "Strak_X_train = pd.DataFrame()\n",
        "Strak_X_train['Method_1'] = train_lgb_pred\n",
        "Strak_X_train['Method_2'] = train_xgb_pred\n",
        "Strak_X_train['Method_3'] = train_gbdt_pred\n",
        "\n",
        "Strak_X_val = pd.DataFrame()\n",
        "Strak_X_val['Method_1'] = val_lgb\n",
        "Strak_X_val['Method_2'] = val_xgb\n",
        "Strak_X_val['Method_3'] = val_gbdt\n",
        "\n",
        "Strak_X_test = pd.DataFrame()\n",
        "Strak_X_test['Method_1'] = subA_lgb\n",
        "Strak_X_test['Method_2'] = subA_xgb\n",
        "Strak_X_test['Method_3'] = subA_gbdt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaEj1Saznbvq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0d7fcef2-7ecb-4088-9c4f-9924f31c40a0"
      },
      "source": [
        "Strak_X_test.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method_1</th>\n",
              "      <th>Method_2</th>\n",
              "      <th>Method_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35657.133698</td>\n",
              "      <td>41310.890625</td>\n",
              "      <td>39127.700530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>238.310188</td>\n",
              "      <td>253.643158</td>\n",
              "      <td>238.626908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6332.940702</td>\n",
              "      <td>7306.389160</td>\n",
              "      <td>7475.811179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11888.836990</td>\n",
              "      <td>11675.732422</td>\n",
              "      <td>12111.413705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>554.332659</td>\n",
              "      <td>511.455994</td>\n",
              "      <td>552.456222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Method_1      Method_2      Method_3\n",
              "0  35657.133698  41310.890625  39127.700530\n",
              "1    238.310188    253.643158    238.626908\n",
              "2   6332.940702   7306.389160   7475.811179\n",
              "3  11888.836990  11675.732422  12111.413705\n",
              "4    554.332659    511.455994    552.456222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32yOeKjvnc6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0fdc0e9f-f0ed-4c6c-f8c5-033f6f56525e"
      },
      "source": [
        "## level2-method \n",
        "model_lr_Stacking = build_model_lr(Strak_X_train,y_train)\n",
        "## 训练集\n",
        "train_pre_Stacking = model_lr_Stacking.predict(Strak_X_train)\n",
        "print('MAE of Stacking-LR:',mean_absolute_error(y_train,train_pre_Stacking))\n",
        "\n",
        "## 验证集\n",
        "val_pre_Stacking = model_lr_Stacking.predict(Strak_X_val)\n",
        "print('MAE of Stacking-LR:',mean_absolute_error(y_val,val_pre_Stacking))\n",
        "\n",
        "## 预测集\n",
        "print('Predict Stacking-LR...')\n",
        "subA_Stacking = model_lr_Stacking.predict(Strak_X_test)\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE of Stacking-LR: 627.2054977432088\n",
            "MAE of Stacking-LR: 710.3035662043364\n",
            "Predict Stacking-LR...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bWs16i3nhdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subA_Stacking[subA_Stacking<10]=10  ## 去除过小的预测值\n",
        "\n",
        "sub = pd.DataFrame()\n",
        "sub['SaleID'] = TestA_data.SaleID\n",
        "sub['price'] = subA_Stacking\n",
        "sub.to_csv('./sub_Stacking.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3TlQC8hnjXx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "97a42cf0-e65d-43fd-f9d3-be881ddea593"
      },
      "source": [
        "print('Sta inf:')\n",
        "Sta_inf(subA_Stacking)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sta inf:\n",
            "_min 10.0\n",
            "_max: 90412.64004381122\n",
            "_mean 5924.668005631054\n",
            "_ptp 90402.64004381122\n",
            "_std 7403.320168943352\n",
            "_var 54809149.523883425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uS6G9K4nmYu",
        "colab_type": "text"
      },
      "source": [
        "# 经验总结\n",
        "\n",
        "比赛的融合这个问题，个人的看法来说其实涉及多个层面，也是提分和提升模型鲁棒性的一种重要方法：\n",
        "\n",
        "\n",
        "\n",
        "*   **结果层面的融合**，这种是最常见的融合方法，其可行的融合方法也有很多，比如根据结果的得分进行加权融合，还可以做Log，exp处理等。在做结果融合的时候，有一个很重要的条件是模型结果的得分要比较近似，然后结果的差异要比较大，这样的结果融合往往有比较好的效果提升。\n",
        "\n",
        "*   **特征层面的融合**，这个层面其实感觉不叫融合，准确说可以叫分割，很多时候如果我们用同种模型训练，可以把特征进行切分给不同的模型，然后在后面进行模型或者结果融合有时也能产生比较好的效果。\n",
        "\n",
        "*   **模型层面的融合**，模型层面的融合可能就涉及模型的堆叠和设计，比如加Staking层，部分模型的结果作为特征输入等，这些就需要多实验和思考了，基于模型层面的融合最好不同模型类型要有一定的差异，用同种模型不同的参数的收益一般是比较小的。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fJilCVInk08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}